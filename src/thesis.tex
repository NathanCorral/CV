\begin{rubric}{Master Thesis}

\iffalse
\entry*[2023]%
\textbf{Stochastic Transformer for Prediction of Multiple Futures}  \newline 
This thesis extended the work of Stochastic Video Generation\footnote{Denton et al., "Stochastic video generation with a learned prior." ICML 2018} and Variational Transformers\footnote{Lin et al., "Variational transformers for diverse response generation." arXiv 2020} into a task-agnostic, stochastic prediction network.  Our novel Stochastic Transformer (STTR) was able to learn a distribution over possible futures in video prediction.  Sampling from the distribution produced one potential continuation of the seed video frames.  We further applied this to the task of human pose prediction. 
\fi
\iffalse
\entry*[2023]%
\textbf{Stochastic Transformer for Prediction of Multiple Futures}  \newline 
This thesis builds upon the foundations of Stochastic Video Generation\footnote{Denton et al., "Stochastic video generation with a learned prior." ICML 2018} and Variational Transformers\footnote{Lin et al., "Variational transformers for diverse response generation." arXiv 2020}, expanding their applications into a versatile, task-agnostic, stochastic prediction network. The novel Stochastic Transformer (STTR) successfully learned a distribution over potential futures in video prediction. By sampling from this distribution, we generated diverse potential continuations of the initial video frames. We also applied this approach to the task of human pose prediction.
\fi

\entry*[2023]%
\textbf{Stochastic Transformer for Prediction of Multiple Futures}  \newline 
This thesis builds upon the foundations of Stochastic Video Generation\footnote{Denton et al., "Stochastic video generation with a learned prior." ICML 2018} and Variational Transformers\footnote{Lin et al., "Variational transformers for diverse response generation." arXiv 2020}, expanding their applications into a versatile, task-agnostic, stochastic prediction network.  This thesis contributed: \newline
\vspace{\CVItemizeHeaderSpacing} \begin{itemize} % Adjust the value as needed
	\setlength{\itemsep}{\CVItemizeSpacing}
	\item A novel transformer-based predictor architecture, able to learn a distribution over potential futures.%  Evidence was shown by providing different, but logical, continuations of a video sequence.
	\item Detailed comparison against other stochastic-based models in video prediction, boasting higher structural similarity in frame-wise comparisons.
	%\item Application in the domain of human pose prediction, generating over 8 seconds of continued walking after the initial 0.3 seconds of seed motion.
\end{itemize}




%\footnote{Denton et al., "Stochastic video generation with a learned prior." ICML 2018}
%\footnote{Lin et al., "Variational transformers for diverse response generation." arXiv 2020}

\end{rubric}