\begin{rubric}{Selbständige Projekte}

\entry*[] \textbf{ROS 2 Whisper Cpp} \hfill 2024 \newline 
\emph{Betreuer} \hfill \href{https://github.com/ros-ai/ros2_whisper/blob/main/doc/harry_potter_sample.gif}{Video}, \href{https://github.com/ros-ai/ros2_whisper}{\faGithub Source} \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}[leftmargin=*, rightmargin=1cm]
	\setlength{\itemsep}{\CVItemizeSpacing}
	\item Als Erweiterung dieses Open-Source-Projekts habe ich eine unbegrenzte Live-Audiotranskription implementiert -- was zur Veröffentlichung der Version 1.4 führte. 
	\item Der C++ Code legt besonderen Wert auf Effizienz und Skalierbarkeit.
	\item Ich habe dieses Projekt zur kontinuierlichen Audiotranskription erfolgreich auf einem Nvidia Jetson Orin NX durchgeführt.
\end{itemize}  

\entry*[] \textbf{ROS 2 Computer Vision} \hfill 2024 \newline \emph{Autor} \hfill \href{https://github.com/NathanCorral/ROS-HF-Vision/blob/main/doc/gifs/ex_german_roads.gif}{Video}, \href{https://github.com/NathanCorral/ROS-HF-Vision/tree/main}{\faGithub Source} \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}[leftmargin=*, rightmargin=1cm] 
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Dieses Projekt implementiert Computer-Vision (CV) Aufgaben (Objekterkennung, Maskenbeschriftung pro Pixel) als parallele ROS 2-Knoten.
	\item Modernste CV Modellen (wie DETR und Maskformer) sind von Hugging Face ~~~~~~~~~~~~ automatisch heruntergeladen.
	\item Die Ergebnisse der CV Modellen, die auf verschiedenen Datensätzen trainiert  ~~~~~~~~~~~~~~ worden sein können, werden von einem globalen Server in einen universellen ~~~~~~~~~~~~~~ Index umgewandelt.  
	\item Diese Pipeline wird entweder auf eine Live-Kameraübertragung oder auf Bilder aus einem vorab trainierten Datensatz angewandt, wobei die Ergebnisse in Echtzeit angezeigt werden, um die durch die Modellwahl verursachte unterschiedliche Verzögerung zu verdeutlichen.
\end{itemize}  

\entry*[] \textbf{Semantic Search using Facebook AI Similarity (FAISS)} \hfill 2024 \newline \emph{Autor} \hfill \href{https://github.com/NathanCorral/Hugging-Face-FAISS-Semantic-Search}{\faGithub Source} \newline
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}[leftmargin=*, rightmargin=1cm] 
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Ich implementiere die ersten Schritte der Retrieval-Augmented Generation (RAG) (endet vor „Generation“).
	\item Ich führe Web-Scraping, Datensatz Einbettung und Ähnlichkeitsbewertung durch, um Dateneinträge basierend auf einer Abfrage in natürlicher Sprache abzurufen.
\end{itemize}  
\begin{comment}
\entry*[2021] \textbf{Temporal Convolutional Network} \newline  
Im Rahmen eines Klassenprojekts haben wir das Multi-Stage Temporal Convolutional Network\footnote{Y. Abu Farha et al., "MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation." CVPR 2019.} in PyTorch neu implementiert. Dieses Projekt erreichte: \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}  
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Verständnis für state-of-the-art (2019) Computer-Vision-Netzwerke zur Klassifikation von Videoaktionen.  
	\item Training und Testen des Modells auf einem Teil eines aktiv genutzten Datensatzes ($\approx$30 \% des Breakfast Actions Dataset).  
	\item Verifizierung der im Paper angegebenen Ergebnisse (66 \% Genauigkeit).  
\end{itemize}  

\entry*[2016] \textbf{Tower of Hanoi} \newline  
Ich programmierte einen Roboterarm, um das Spiel Tower of Hanoi vollständig automatisiert zu spielen. Die Projektziele umfassten: \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}  
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Berechnung der inversen Kinematik für einen ROS-gesteuerten Rhino-RX2-Arm und deren Programmierung in C++.  
	\item Anbringung einer nach unten gerichteten Kamera und Entwicklung eines Computer-Vision-Nodes zur Identifizierung von Blöcken in der Roboter-Ebene.  
	\item Festlegung der Turmzentren und Programmierung der Spiellogik von Tower of Hanoi.  
\end{itemize}  
\end{comment}


\end{rubric}

