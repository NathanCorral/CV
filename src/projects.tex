\begin{rubric}{Projekte}

\entry*[2024] \textbf{ROS 2 Whisper} \hfill \href{https://github.com/ros-ai/ros2_whisper/blob/main/doc/harry_potter_sample.gif}{Video}, \href{https://github.com/ros-ai/ros2_whisper}{\faGithub Source} \newline  
Als Erweiterung dieses Open-Source-Projekts habe ich eine grenzenlose, Live-Audiotranskription implementiert. Mein Beitrag hat dazu geführt, dass ich ein aktiver Betreuer dieses Projekts wurde. Der in C++ geschriebene Code legt besonderen Fokus auf: \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}  
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Skalierbarkeit:  Through using both inheritance and composition in object-oriented programming behavior.
	\item Effizienz:  Through intentional memory management, thread-safe callbacks and work splitting across multiple nodes.
	\item Einfachheit in der durchdachten Implementierung complex merging algorithms.
\end{itemize}  

\entry*[2024] \textbf{ROS 2 Computer Vision} \hfill \href{https://github.com/NathanCorral/ROS-HF-Vision/blob/main/doc/gifs/ex_german_roads.gif}{Video}, \href{https://github.com/NathanCorral/ROS-HF-Vision/tree/main}{\faGithub Source} \newline  
Das Ausführen mehrerer Computer-Vision-Modelle (DETR, Maskformer), die für verschiedene Datensätze/Aufgaben trainiert wurden, auf einem Live-Kamerastream stellt mehrere Implementierungsherausforderungen dar. Dieses Python-Repository bietet eine Lösung für: \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}  
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Das Herunterladen und Ausführen von State-of-the-Art-Modellen aus Hugging Face als asynchrone ROS 2 Nodes.  
	\item Das Hosten eines Label Server, um Modell-Ausgaben in einer globalen Datenbank neu zu adressieren.  
	\item Die Anzeige von Segmentation Masks und Bounding Boxes als Matplotlib Animations.  
	\item Das Veröffentlichen von Datensatzbildern zur wiederholbaren Evaluierung von CV-Modellen.  
\end{itemize}  

\entry*[2024] \textbf{Semantic Search using Facebook AI Similarity (FAISS)} \hfill \href{https://github.com/NathanCorral/Hugging-Face-FAISS-Semantic-Search}{\faGithub Source} \newline
Dieses Projekt implementiert die ersten Schritte der Retrieval-Augmented Generation (RAG) (endet vor „Generation“). Ich führe Web-Scraping, Datensatz-/Abfrage-Einbettung und Ähnlichkeitsbewertung durch, um Dateneinträge basierend auf einer Abfrage in natürlicher Sprache abzurufen.

\begin{comment}
\entry*[2021] \textbf{Temporal Convolutional Network} \newline  
Im Rahmen eines Klassenprojekts haben wir das Multi-Stage Temporal Convolutional Network\footnote{Y. Abu Farha et al., "MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation." CVPR 2019.} in PyTorch neu implementiert. Dieses Projekt erreichte: \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}  
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Verständnis für state-of-the-art (2019) Computer-Vision-Netzwerke zur Klassifikation von Videoaktionen.  
	\item Training und Testen des Modells auf einem Teil eines aktiv genutzten Datensatzes ($\approx$30 \% des Breakfast Actions Dataset).  
	\item Verifizierung der im Paper angegebenen Ergebnisse (66 \% Genauigkeit).  
\end{itemize}  

\entry*[2016] \textbf{Tower of Hanoi} \newline  
Ich programmierte einen Roboterarm, um das Spiel Tower of Hanoi vollständig automatisiert zu spielen. Die Projektziele umfassten: \newline  
\vspace{\CVItemizeHeaderSpacing} \begin{itemize}  
	\setlength{\itemsep}{\CVItemizeSpacing}  
	\item Berechnung der inversen Kinematik für einen ROS-gesteuerten Rhino-RX2-Arm und deren Programmierung in C++.  
	\item Anbringung einer nach unten gerichteten Kamera und Entwicklung eines Computer-Vision-Nodes zur Identifizierung von Blöcken in der Roboter-Ebene.  
	\item Festlegung der Turmzentren und Programmierung der Spiellogik von Tower of Hanoi.  
\end{itemize}  
\end{comment}


\end{rubric}

